---
gitshrink:
  title: Git repository liposuction
  body: |
    Many aeons ago, my organization managed an internal git server for all our
    team's source code. Eventually a decision was made to migrate to GitHub,
    starting first with new repositories and then later transferring existing
    ones. All went well until they got to the last and most critical of all the
    repositories--a 20+ year old behemoth that itself started life as a migrated
    Subversion repository. Over the decades, users had made the poor decision to
    check in large binaries. These binaries were eventually removed, but once
    they're in git history the binary content is checked in forever, taking up
    space. GitHub imposes a limit on repo import of a maximum 3 GB repo size and
    100 MB maximum checked-in file size--our repo exceeded both.<br /><br />

    I presented two potential solutions--adopt <a
    href="https://git-lfs.github.com/">Git LFS&#x1F5D7;</a>, performing a
    migration of binary files in history to LFS using <a
    href="https://github.com/bozaro/git-lfs-migrate">git-lfs-migrate&#x1F5D7;</a>,
    or simply strip all large files from history using <a
    href="https://rtyley.github.io/bfg-repo-cleaner/">BFG Repo
    Cleaner&#x1F5D7;</a>. Migrating to LFS would preserve git history but incur
    a storage cost on GitHub, whereas using BFG Repo Cleaner would alter
    historical commit IDs as all commit hashes would have to be recalculated
    after the content was removed from history. We decided that, given our
    relatively small team, altering history was not a deal-beaker and we could
    simply all re-clone after the repository was cleaned up. In the end, BFG
    Repo Cleaner shrunk the repository to around 450 MB, a nearly 90% decrease
    in footprint. As an added bonus, cloning and navigating the repo became much
    less painful.
composeconvert:
  title: Convert Compose v2 to v3
  body: |
    Our team has long-used <code>docker-compose</code> to manage container
    workloads, writing compose files in the compose v2 format. I was tasked with
    migrating us to Docker Swarm Mode which exclusively uses compose v3. I was
    immediately concerned with the implications of maintaining two separate
    compose files per environment and the potential that creates for
    configuration drift, so instead I chose to develop a tool to translate a
    given compose file in the v2 format to v3. This way, we would continue to
    use the same v2 files we always had, and the deploy pipeline would
    automatically convert the file to the required format at deploy time.<br
    /><br />

    Initially I thought this would be a straightforward case of renaming certain
    yaml keys, or trimming unneeded deprecated configurations. As I began
    though, I realized that our organization made heavy use of the
    <code>depends_on</code> and <code>extends</code> features of compose v2 that
    had been deprecated with no equivalent or replacement as of version 3.8. The
    challenge then became to find a way to replicate the behavior these two
    configurations offered during translation.
  links:
    - title: compose-convert.py - Make a best-effort translation of compose v2 to Swarm's compose v3
      href: placeholder

docklog:
  title: <code>docker logs</code> for multiple containers
  body: |
    If you simply google the title above, you'll see very many people asking how
    to accomplish this task. The demand is so great that it's honestly amazing
    that Docker have not extended the <code>docker logs</code> command to
    support multiple containers. Even <code>docker-compose logs</code> will
    output a stream of logs from all containers defined in the compose file! It
    seems to be an obvious use-case to everyone but Docker themselves. So to
    right this wrong I created a tool for myself that streams multiple container
    logs directly from the Docker API. I placed a hard limit of eight
    simultaneous streams in case this much concurrency could be a problem for
    the API, though I've done no testing or research to see if this is even the
    case.
  links:
    - title: docklog.py - Tail many container logs in parallel
      href: https://github.com/a-abella/docklog

elasticingestnode:
  title: Elasticsearch ingest pipeline query string parsing
  body: |
    Our team was looking for a way to aggregate and report on certain API usage
    metrics which we could only retrieve from Docker-based HTTP logs. I had
    previously implemented Docker log aggregation with <a
    href="https://www.elastic.co/beats/filebeat">Filebeat&#x1F5D7;</a> and <a
    href="https://www.elastic.co/cloud/">Elastic Cloud&#x1F5D7;</a>. The default
    Filebeat modules do a great job of parsing common known formats, like
    Apache's and NGINX's standard HTTP log format, which get chopped up and
    indexed as individual searchable and aggregatable fields. One of the
    features of Elasticsearch is the <a
    href="https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html">ingest
    pipeline&#x1F5D7;</a> where you can define parsing and mutation rules for
    inputs prior to indexing. Many people use Logstash as part of the "ELK
    stack" for this purpose, but it's less commonly known that parsing and
    mutation can also be done on Elasticsearch itself, making use of existing
    compute and placing the parse logic closer to the data resulting in a
    logging stack with fewer moving parts.<br /><br />

    To accomplish the task of parsing our API metrics, I took the existing
    NGINX/HTTP log ingest pipeline (provided by Filebeat's NGINX module) and
    extended it with additional parsing on the query string. Our goal was to be
    able to search and aggregate over each individual key and value pair in the
    URL query string when the URL path targets a subset of API endpoints. To
    that end, I added a <code>grok</code> pattern that would take each query
    string key and create an indexed keyword field from it, and assign that
    field the value from the query string. This made possible aggregations like
    "get count of requests grouped by query string key time_range." The
    resulting data from this example would be very valuable for determining
    platform improvements, like optimizing web server cache time and InfluxDB
    shard group durations.

geninfluxdata:
  title: InfluxDB sample data generator
  body: |
    Time-series data is the heart of the application I support. Our teams'
    primary customer-facing product is (for the most part) a series of
    dashboards and reports displaying metric data backended by <a
    href="https://www.influxdata.com/">InfluxDB&#x1F5D7;</a>. One day one of our
    QA engineers was expressing that it would be easier to compare the
    functionality of charts and graphs across different code versions if they
    were always rendering the same data, regardless of <i>when</i> the
    comparison was being done.<br /><br />

    I took it upon myself to write a tool that could output a consistent metric
    set to an InflxuDB instance for any arbitrary window of time. Using this
    tool, the QA team could eliminate variability in data and perform more
    consistent testing.
  links:
  - title: write-sample-metrics.py - generate and write a reproducible set of metric data to InfluxDB
    href: https://github.com/a-abella/write-sample-metrics

dynamicinventory:
  title: Ansible dynamic inventory
  body: |
    I came into a new role as a DevOps Engineer at <a
    href="https://smartbear.com/" style="color:#f5710f">SmartBear&#x1F5D7;</a>,
    working on an application with some pretty unique infrastructure challenges.
    In addition to a fairly standard AWS technology stack, my team had to manage
    a fleet of about 300 additional servers located in around 30 different
    countries around the world hosted in all manner of ways--colocations,
    dedicated server providers, VPS services, and larger cloud providers. This
    situation disallowed the "cattle, not pets" philosophy that is promoted in
    modern DevOps and SRE.<br /><br />

    Idempotent infrastructure for these 300-ish servers was not possible since
    we had no direct control over system images or ad-hoc infrastructure
    deployments. Given the restriction imposed by the underlying infrastructure,
    <a
    href="https://github.com/ansible/ansible"><code>ansible&#x1F5D7;</code></a>
    was the primary tool used to align systems with as much identicality as we
    could manage. To that end, <a
    href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">ansible
    dynamic inventory&#x1F5D7;</a> provided a very powerful way to centrally
    configure Ansible-managed hosts.<br /><br />

    Fortunately for us, our application already relied on a MySQL server
    inventory table that we could leverage for Ansible inventory. A
    <code>host_type</code> field mapped directly to Ansible host groups, and a
    delimited string of feature flags could be passed as an array hostvar
    enabling conditional execution of tasks. With these already in-hand, all
    that was needed was a script to format each host row into Ansible
    inventory-compatible JSON.

locateusers:
  title: Locate users on the network
  body: |
    No matter how many times it has been brought up, a large percentage of
    ticket submissions would come in with no identifying information on the
    affected workstation. Growing frustrated, I took matters into my own
    hands. I wrote a set of functions to search the organization's file
    servers for connected users and their respective connected IPs. Since
    every user accesses at least one file share, this was a fairly reliable
    method of discovery. And since it didn't rely on querying neighboring
    workstations, it was significantly faster than methods like PSTools'
    <code>PSLoggedOn.exe</code>.
  links:
  - title: locateUser.ps1 - Quickly find where a user is logged in
    href: https://github.com/a-abella/locateUser

statefulreboots:
  title: Stateful workstation reboots
  body: |
    For some unknown reason, our standard nightly workstation reboot GPO would
    fail to wake clients for the reboot task. Looking for alternative
    solutions, we decided on rebooting workstations after an explicit logout.
    However, disconnected sessions and the Switch User button meant that if a
    second user logged in and out, existing disconnected sessions would be
    lost on the reboot, even if that session was just one hour old while the
    user was out to lunch.<br /><br />

    By parsing <code>query user</code> output, we could reboot conditionally
    based on the state of active and disconnected sessions. We could even get
    the idle times of disconnected sessions to only reboot when we could
    consider it "safe." Doing this, we achieved our goal of frequent
    workstation reboots but without the data loss risk typically associated
    with such policies.
  links:
    - title: stateful-station-reboot.ps1 - Session-aware regular workstation restarts
      href: https://github.com/a-abella/stateful-station-reboot

ransomdetection:
  title: Ransomware detection with inotify
  body: |
    Most ransomware variants encrypt volumes recursive and usually traverse a
    file system alphabetically. Knowing this, we can lay bait for ransomware,
    and then sound the alarm when notice something suspicious. When working on
    my <a class="projlink" href="#smbdfssetup">Samba DFS project</a>, I
    created world-writable hidden directories at the root of every share, and
    named them so they sat first in alphabetical order. In each directory were
    thousands of almost-empty plaintext files. Using <a class="projlink"
    href="https://github.com/rvoicilas/inotify-tools"><code>inotify-tools&#x1F5D7;</code></a>
    to interface with Linux's <code>inotify()</code> function, I set up an
    inode watch on every file of each hidden directory. When a threshold value
    of files are modified or deleted, the server fires off an email containing
    the connection information of the user(s) and IP(s) accessing those bait
    files.<br /><br />

    While the encryption program takes its time to encrypt all the thousands
    of files (usually a handful of minutes), we are afforded the opportunity
    to verify and then kill the malicious process ID. To take it a step
    further, we can even block the IP on every shares' firewall with a single
    Ansible command. The process is further automatable by killing the PID and
    setting the firewall rule at another, higher threshold. Using this
    approach, we've lowered our average frequency of ransomware events
    (defined as events requiring a file system restore) from 1-2 per month to
    zero.
  links:
    - title: ransom-alarm.sh - Monitoring for ransomware and other intrusion
      href: https://github.com/a-abella/ransom-alarm.sh

smbdfssetup:
  title: Automated Samba share deployments for DFS
  body: |
    At my first organization, the existing network storage solution was a
    single Windows Share on bare metal. The server was about five years old
    and supported the entire 1,200 person organization. When ransomware got
    popular, the lack of a proper permissions structure left it very
    vulnerable to attack. I was tasked with decentralizing our storage, and
    the solution I devised was a multi-server, department-segregated Windows
    Domain DFS Namespace where the shared folders were actually Linux Samba
    shares. Through the Samba configuration I could "invisibly" fine-tune
    access control. Running the shares on Linux servers also gave me access to
    tools like <code>inotify()</code> and <code>auditd</code> for rudimentary
    intrusion detection.<br /><br />

    At final count, I was planning 11 separate shares on 7-8 separate CentOS 7
    hosts. To facilitate the deployment process, I developed a guided
    interactive script to automatically manage the Samba and Winbind
    configurations, as well as handle LVM management and base permissions.
  links:
    - title: smb-dfs-share-setup.py - Automated per-department Samba share configuration
      href: https://github.com/a-abella/smb-dfs-share-setup.py

adaccounttool:
  title: Bulk AD account management with Exchange support
  body: |
    My first systems administration position was in a call center, and among
    my responsibilities was Active Directory administration. Due to the nature
    of the call center business, customer service representative turnover
    rates were high enough that user account administration was a hassle.
    Especially in the holiday seasons, we would frequently receive lists of
    new hires and terminations <b>60+</b> users long. Prior to my scripted
    solution, the established method of administering user accounts was to
    manually create or delete them one-by-one in the AD Users & Groups GUI.
    Needless to say, as the new-hires and terminations lists grew longer, I
    grew more and more impatient.<br/><br/>

    My objective was to make the least annoying user management script I
    could. No pre-formatted CSV files needed, or anything or the sort. Just
    select an OU from a graphical dialog, paste in whole lists of proper names
    (with some minor formatting caveats), follow the prompts. Easy,
    annoyance-free, and greatly enhanced ticket turnaround time. There's still
    quite a few more features worth adding, but even now it's one of the more
    valuable tools I've created for myself.
  links:
    - title: usermanagement.ps1 - AD and Exchange account management
      href: https://github.com/a-abella/usermanagement.ps1

psnettools:
  title: Network querying & WakeOnLan with AD integration
  body: |
    When working on desktop inventory, provisioning, or deployment projects I
    would frequently need to monitor and maintain the online status of a
    subset of PCs within the organization. For example, when taking software
    inventory of only a single OU worth of PCs, I would first need to
    determine the sleep/wake status of all the PCs in the OU, wake the ones
    that are unresponsive, and keep them awake until the task has been
    completed. The company I worked at when I wrote these tools had a very
    "boots-on-ground" approach to this problem (i.e., walk to the computers
    and slap the spacebars), which I found less than efficient. I wrote these
    tools to solve that.
  links:
    - title: Wake-Send.ps1 - WakeOnLan packet constructor with AD integration
      href: https://github.com/a-abella/Wake-Send.ps1
    - title: Mass-Ping.ps1 - Quickly get online status of groups of hosts with AD integration
      href: https://github.com/a-abella/Mass-Ping.ps1

macscanner:
  title: Compiling MAC address data for WakeOnLan
  body: |
    Developed in conjunction with my <a class="projlink"
    href="#psnettools">Wake-Send.ps1 PowerShell script</a>, I needed a
    reliable and up-to-date source of device MAC addresses on the network so I
    could construct a <a class="projlink"
    href="https://en.wikipedia.org/wiki/Wake-on-LAN#Magic_packet"
    target="_blank">magic packet&#x1F5D7;</a> containing a target PC's MAC
    address data. Enter macscanner.sh. Parses <code>nmap</code> output,
    self-cleans repeat entries, is multi-hostname-aware, and requires no
    maintenance or afterthought. Runs on any Linux server you have lying
    around that's online on your target network. I run it on a 30 minute cron,
    and <code>scp</code> it to a network location where Wake-Send.ps1 can
    access it.
  links:
    - title: macscanner.sh source and documentation
      href: https://github.com/a-abella/macscanner.sh

seething:
  title: Seething Corruption Trainer
  body: |
    A simple Python script to help memorize the Seething Corruption
    positioning call-outs on World of Warcraft's Mythic Archimonde encounter.
    Written because I'm bad at getting over failure. Pretty much useless to
    anyone but myself.
  links:
    - title: Source and sample gif
      href: https://github.com/a-abella/seething-corruption-trainer

antonioabellacom:
  title: antonioabella.com
  body: |
    This site, hosted on a Digital Ocean Ubuntu LTS (14.04) VPS serving
    virtualhost pages with nginx and php-fpm. Created so I can hand out a
    website name and craftily appear to be a professional.
  links:
    - title: Page sources, configs, and changelogs
      href: https://github.com/a-abella/antonioabella.com

cvguild:
  title: Desktop and mobile sites, form in PHP and JQuery, VOIP services
  body: |
    A landing portal and application form for a World of Warcraft raiding
    guild, server as a virtual host on this same server. Implements php-fpm
    for form manipulation and jQuery 1.11.2 via Google CDN. The desktop
    landing page uses a parallax effect design created in pure CSS. The mobile
    site is responsively designed for any resolution by leveraging the CSS3
    viewport-height attribute. This server also hosts a Mumble VOIP server
    implementing SSL certificate validation for registered and elevated users.
  links:
    - title: Desktop landing page
      href: https://www.cv-guild.com
    - title: Mobile landing page
      href: https://m.cv-guild.com
    - title: PHP application form
      href: https://www.cv-guild.com/app.php
    - title: Desktop site page sources and configs
      href: https://github.com/a-abella/convictionguild
    - title: Mobile site page sources and configs
      href: https://github.com/a-abella/convictionmobile

fiuserver:
  title: CentOS 5.11 multi-role term project
  body: |
    A CentOS 5.11 server with SaltStack configuration management, several web
    services, Asterisk PBX, instant messaging server, extended logging
    services, backup management, network printing services, and more. Ran as a
    guest within a VMWare ESXi 5.5 host.
  links:
    - title: Configs, binaries, and served web pages
      href: https://github.com/a-abella/centos-server
    - title: All documentation as plaintext
      href: docs/centosdocs/howtopage.html

adhomelab:
  title: Windows AD/Exchange virtual lab
  body: |
    A virtual network hosted on VMWare Workstation 11 consisting of two
    Windows Server 2012 R2 servers, one CentOS 7 server, one Windows 7
    Professional client, one Mac OS X 10.11 client, and one CentOS 7 client.
    One Server 2012 instance runs Active Directory, DNS, DHCP, and Routing and
    Remote Access to serve as a border router granting the virtual network
    internet connectivity. The second Server 2012 instance runs Exchange and
    IIS. The Linux server runs Apache and other miscellaneous services. The
    Linux machines authenticate to Active Directory with Samba/Kerberos, and
    the OS X client binds to AD with the in-built OS X OpenDirectory
    utilities.
  links:
    - title: Configs and documentation
      href: docs/adlabdocs/adlabindex.html

kvm:
  title: Linux KVM hypervisor with KVM/Qemu Windows instance using IOMMU
  body: |
    A typical workstation machine running Arch Linux as the host alongside a
    Windows VM via KVM/Qemu. IOMMU (Input/Output Memory Management Unit)
    allows certain hypervisors to take control of assigned hardware devices
    including PCI controllers. In this application I pass a discrete GPU to
    the Windows VM which allows up to 95% of the native graphical performance
    within the VM enabling certain GPU intensive tasks such as gaming, video
    rendering, and hardware accelerated decode of very high resolution video.
    The two machines run concurrently with each GPU connected to its own
    monitor.
  links:
    - title: KVM/Qemu Configurations
      href: ""
    - title: Scripts and additional configurations
      href: ""
    - title: Extended explanations and instructions
      href: ""