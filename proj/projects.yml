---
featscale:
  title: Automatic vertical scaling for QA agility
  body: |
    Had myself a fun one-day project at the behest of one of our QA Engineers.
    My <a class="projlink" target="_self" href="#dynamicenvs">self-service feature env
    system</a> was a hit with our devs, but created unintended headaches for
    testers. On the one hand, independent feature stacks allowed for extremely
    easy A/B comparisons for QA. On the other, our high rate of feature
    development meant we ended up with way more feature envs than we initially
    planned for, and cost-saving measures became necessary. One such measure was
    placing a fairly low upper-limit on developer-requestable instance sizes.
    This was fine for the devs who mostly idled or ran single-thread tests
    against their environments, but our QA test  suffered.<br /><br />

    To offset load-related timeouts, the QA Engineers reduced their test threads
    which resulted in much longer testing durations. The rate of feature
    development was threatening to outpace the rate of testing. I was asked to
    automate a process for scaling up instance sizes at test initialization,
    then scaling down upon completion.<br /><br />

    For the most part this was a non-issue, except the feature environments were
    provisioned from a shared Terraform state (something that is starting to
    become its own problem), which grew to the point of annoyingly long
    <code>terraform plan</code> times. The solution is simple but
    undesirable--Terraform supplies a <code>-target=</code> command line option,
    allowing one to state-refresh, plan, and apply changes to individual modules
    or even individual resources using resource addressing. <i>However</i>,
    Terraform itself chides you for even using it:<br />

    <pre><code class="language-shell">╷
    │ Warning: Resource targeting is in effect
    │
    │ The -target option is not for routine use, and is provided only for exceptional situations such as recovering from errors or mistakes, or when Terraform specifically suggests to use it as part of an
    │ error message.
    ╵
    </code></pre>

    With great shame and heavy heart I write that I have sinned for, I have
    designed a heavily-used internal system that makes frequent use of Terraform
    resource targeting. But hey, it's working great.

zeptrials:
  title: Customer environment provisioning API with AWS Lambda
  body: |
    At SmartBear, one of our most in-demand SaaS products is <a
    href="https://smartbear.com/test-management/zephyr-enterprise/">Zephyr
    Enterprise</a>. Unfortunately, for years the customer trial spin-up
    automation was poorly designed and prospective customers would face a wait
    time of well over 25 minutes. The sales team was rightfully concerned with
    the number of leads lost to slow trial delivery.<br /><br />

    We set out to redesign the entire trial provisioning pipeline with a focus
    on performance, self-service, and ease of integration. From the outset we
    knew we wanted an API that the marketing team could use to request trials
    and ping for trial status. The same API would offer trial extension and
    termination functions for the sales team.<br /><br />
    
    As trials are inherently ephemeral, we knew we wanted to provision all
    infrastructure with AWS SDKs instead of stateful IaC tools like Terraform
    which can have notoriously slow executions due to state refreshes. We
    selected Lambda for a zero-maintenance runtime environment and Python +
    boto3 for maintainability as it is a <i>lingua franca</i> among our DevOps
    teams. Given that SmartBear is the steward of the open-source Swagger suite
    of API development tools, we naturally elected to use AWS API Gateway for
    request routing as it natively consumes OpenAPI/Swagger API definitions to
    scaffold your Gateway for you.<br /> <br />

    Our team can proudly say that we delivered a fully-featured SaaS trial
    management API to the sales and marketing departments that reduced customer
    wait times from 25+ minutes to approximately 30 seconds. 


dynamicenvs:
  title: Transient environments for Docker Swarm
  body: |
    Our development team grew to a point where our existing handful of Docker
    dev and QA environments became a bottleneck and started causing contention
    over feature deployments. In the past with a smaller team, it was uncommon
    for two or more developers to be simultaneously but separately working on
    the same microservices. To deal with this, I was tasked with finding a way
    to grant developers on-demand, dynamic, individual environments within the
    development Swarm cluster. Accomplishing this required every tool in our
    team's arsenal; Terraform, Python, Groovy, MySQL, Ansible, shell scripts,
    Makefiles, InfluxDB, and Jenkins came together like Voltron to build a
    system that could:

    <ul>
      <li>Provision and assign individualized AWS infrastructure</li> <li>Tag
      all resources for cost analysis per-environment and per-user</li>
      <li>Isolate Docker image builds to avoid poisoning each other's build
      caches</li> <li>Support any size deployment, from individual microservices
      to full stack</li> <li>Dynamically modify container environments as
      neighbor services are spun up or down</li> <li>Alert on deployment
      inactivity to ensure against abandoned environments</li>
    </ul>

    <p>The centerpieces that made this system possible are the <a
    href="https://registry.terraform.io/providers/hashicorp/external/latest/docs/data-sources/data_source">Terraform
    <code>external</code> datasource</a> which enabled infrastructure
    configurations to be fetched and generated from a centralized MySQL
    environment metadata table, the Ansible <a
    href="https://docs.ansible.com/ansible/latest/collections/community/docker/docker_swarm_module.html#ansible-collections-community-docker-docker-swarm-module"><code>docker_swarm</code></a>
    and <a
    href="https://docs.ansible.com/ansible/latest/collections/community/docker/docker_node_module.html#ansible-collections-community-docker-docker-node-module"><code>docker_node</code></a>
    modules with which EC2 instances could be dynamically added to and removed
    from the Swarm, and the Jenkins <a
    href="https://plugins.jenkins.io/extended-choice-parameter/">Extended Choice
    Parameter plugin</a> with which complex forms could be presented to users
    for fine-grained control over environment configuration.

gitshrink:
  title: Trimming git object history
  body: |
    Many aeons ago, my organization managed an internal git server for all our
    team's source code. Eventually a decision was made to migrate to GitHub,
    starting first with new repositories and then later transferring existing
    ones. All went well until they got to the last and most critical of all the
    repositories--a 20+ year old behemoth that itself started life as a migrated
    Subversion repository. Over the decades, users had made the poor decision to
    check in large binaries. These binaries were eventually removed, but once
    they're in git history the binary content is checked in forever, taking up
    space. GitHub imposes a limit on repo import of a maximum 3 GB repo size and
    100 MB maximum checked-in file size--our repo exceeded both.<br /><br />

    I presented two potential solutions--adopt <a
    href="https://git-lfs.github.com/">Git LFS</a>, performing a migration of
    binary files in history to LFS using <a
    href="https://github.com/bozaro/git-lfs-migrate">git-lfs-migrate</a>, or
    simply strip all large files from history using <a
    href="https://rtyley.github.io/bfg-repo-cleaner/">BFG Repo Cleaner</a>.
    Migrating to LFS would preserve git history but incur a storage cost on
    GitHub, whereas using BFG Repo Cleaner would alter historical commit IDs as
    all commit hashes would have to be recalculated after the content was
    removed from history. We decided that, given our relatively small team,
    altering history was not a deal-beaker and we could simply all re-clone
    after the repository was cleaned up. In the end, BFG Repo Cleaner shrunk the
    repository to around 450 MB, a nearly 90% decrease in footprint.

composeconvert:
  title: Convert Compose v2 to v3
  body: |
    Our team has long-used <code>docker-compose</code> to manage container
    workloads, writing compose files in the compose v2 format. I was tasked with
    migrating us to Docker Swarm Mode which exclusively uses compose v3. I was
    immediately concerned with the implications of maintaining two separate
    compose files per environment and the potential that creates for
    configuration drift, so instead I chose to develop a tool to translate a
    given compose file in the v2 format to v3. This way, we would continue to
    use the same v2 files we always had, and the deploy pipeline would
    automatically convert the file to the required format at deploy time.<br
    /><br />

    Initially I thought this would be a straightforward case of renaming certain
    yaml keys, or trimming unneeded deprecated configurations. As I began
    though, I realized that our organization made heavy use of the
    <code>depends_on</code> and <code>extends</code> features of compose v2 that
    had been deprecated with no equivalent or replacement as of version 3.8. The
    challenge then became to find a way to replicate the behaviors v2 offered
    during translation.
  # links:
  #   - title: compose-convert.py - Make a best-effort translation of compose v2 to Swarm's compose v3
  #     href: placeholder

docklog:
  title: <code>docker logs</code> for multiple containers
  body: |
    If you simply google the title above, you'll see very many people asking how
    to accomplish this task. The demand is so great that it's honestly amazing
    that Docker have not extended the <code>docker logs</code> command to
    support multiple containers. Even <code>docker-compose logs</code> will
    output a stream of logs from all containers defined in the compose file! It
    seems to be an obvious use-case to everyone but Docker themselves. So to
    right this wrong I created a tool for myself that streams multiple container
    logs directly from the Docker API. I placed a hard limit of eight
    simultaneous streams in case this much concurrency could be a problem for
    the API, though I've done no testing or research to see if this is even the
    case.
  links:
    - title: docklog.py - Tail many container logs in parallel
      href: https://github.com/a-abella/docklog

elasticingestnode:
  title: Elasticsearch HTTP log query string indexing
  body: |
    Our team was looking for a way to aggregate and report on certain API usage
    metrics which we could only retrieve from Docker-based HTTP logs. I had
    previously implemented Docker log aggregation with <a
    href="https://www.elastic.co/beats/filebeat">Filebeat</a> and <a
    href="https://www.elastic.co/cloud/">Elastic Cloud</a>. One of the
    features of Elasticsearch is the <a
    href="https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html">ingest
    pipeline</a> where you can define parsing and mutation rules for
    inputs prior to indexing. Many people use Logstash as part of the "ELK
    stack" for this purpose, but it's less commonly known that parsing and
    mutation can also be done on Elasticsearch itself, making use of existing
    compute and reducing complexity in the logging stack.<br /><br />

    I took the existing NGINX log ingest pipeline (provided by Filebeat) and
    extended it to <code>grok</code> out the query string pattern from the
    request URL. Once I had the query string separated, it could be split on the
    <code>&</code> character and each key-value pair could be loaded into the
    index using the <code>kv</code> processor. This made possible aggregation
    queries to the effect of <code>"select count(requests) where
    url.fields.time_range is not NULL group by url.fields.time_range"</code>.
    The resulting data from this example would be very valuable for determining
    platform improvements, like optimizing web server cache time and InfluxDB
    shard group durations.<br /><br />

    <pre><code class="language-json">{
      "grok": {
        "field": "url.original",
        "patterns": [
          "%{GREEDYDATA:trash}\\?%{GREEDYDATA:url.querystring}",
          ""
        ],
        "ignore_missing": true
      }
    },
    {
      "kv": {
        "field": "url.querystring",
        "field_split": "&",
        "value_split": "=",
        "target_field": "url.fields",
        "strip_brackets": true,
        "ignore_missing": true
      }
    },
    {
      "remove": {
      "field": "url.querystring",
      "ignore_missing": true
      }
    }
    </code></pre>

zabbixactions:
  title: Zabbix problem auto-resolution
  body: |
    Much of modern operations is based around automation. Monitoring and
    observability are all very important, but if a person has to react and
    intervene on monitoring alerts then that person becomes a bottleneck.
    Eventually it was realized that if procedures and remediations could be
    defined for operators in runbooks, then there's no reason that runbook
    couldn't be executed automatically--this gave birth to tools like <a
    href="https://www.rundeck.com/">Rundeck</a>.<br /><br />

    We use many different monitoring tools internally. One of these tools is <a
    href="https://www.zabbix.com/">Zabbix</a>, a MySQL-based system
    monitoring suite. We like Zabbix for its flexibility--absolutely any
    arbitrary data that you can generate at a shell prompt can be regularly
    collected and monitored by Zabbix without the same kind of cardinality
    issues that would affect most time-series based monitoring tools. An
    extension of this capability is Zabbix Actions; the same way arbitrary shell
    commands can be executed on remote hosts to collect data, arbitrary shell
    commands can be executed when trigger conditions are met. Assume a trigger
    that fires when a process <code>$p</code> dies, an Action can simply start
    <code>$p</code>.<br /><br />

    There was one problem to overcome with this: preventing Zabbix from
    interfering with an operator. If for whatever reason an operator was
    intentionally making changes that could trigger alerts, we didn't want
    Zabbix to then be simultaneously firing off commands, causing confusion and
    inconsistency. So a crucial requirement was to implement some form of idle
    session detection--if users were logged in and not idle, then Zabbix should
    never execute actions on that machine. If there were no sessions or idle
    sessions, then Zabbix could go ahead and take its remediation steps. We
    parse the <code>w</code> command for idle times, which counts time since the
    user's last keystroke.
  # links:
  #   - title: zabbix-actions.sh - a wrapper script for safely executing pre-defined Zabbix actions
  #     href: https://github.com/a-abella/zabbix-actions

geninfluxdata:
  title: InfluxDB sample data generator
  body: |
    Time-series data is at the heart of the application I support. Our teams'
    primary customer-facing product is (for the most part) a series of
    dashboards and reports displaying metric data backended by <a
    href="https://www.influxdata.com/">InfluxDB</a>. One day one of our
    QA engineers was expressing that it would be easier to compare the
    functionality of charts and graphs across different code versions if they
    were always rendering the same data, regardless of <i>when</i> the
    comparison was being done.<br /><br />

    I took it upon myself to write a tool that could output a consistent metric
    set to an InflxuDB instance for any arbitrary window of time. Using this
    tool, the QA team could eliminate variability in data and perform more
    consistent testing. Eventually I would like to extend this tool to output
    data for other commonly used time-series databases, like Prometheus and
    Graphite.
  # links:
  # - title: gen-sample-metrics.py - generate and write a reproducible set of metric data to InfluxDB
  #   href: https://github.com/a-abella/gen-sample-metrics

dynamicinventory:
  title: Ansible dynamic inventory
  body: |
    I came into a new role as a DevOps Engineer at <a
    href="https://smartbear.com/" style="color:#f5710f">SmartBear</a>,
    working on an application with some pretty unique infrastructure challenges.
    In addition to a fairly standard AWS technology stack, my team had to manage
    a fleet of about 300 additional servers located in around 30 different
    countries around the world hosted in all manner of ways--colocations,
    dedicated server providers, VPS services, and larger cloud providers. This
    situation disallowed the "cattle, not pets" philosophy that is promoted in
    modern DevOps and SRE.<br /><br />

    Idempotent infrastructure for these 300-ish servers was not possible since
    we had no direct control over system images or ad-hoc infrastructure
    deployments. Given the restriction imposed by the underlying infrastructure,
    <a
    href="https://github.com/ansible/ansible"><code>ansible</code></a>
    was the primary tool used to align systems with as much identicality as we
    could manage. To that end, <a
    href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">ansible
    dynamic inventory</a> provided a very powerful way to centrally
    configure Ansible-managed hosts.<br /><br />

    Fortunately for us, our application already relied on a MySQL server
    inventory table that we could leverage for Ansible inventory. A
    <code>host_type</code> field mapped directly to Ansible host groups, and a
    delimited string of feature flags could be passed as an array hostvar
    enabling conditional execution of tasks. With these already in-hand, all
    that was needed was a script to format each host row into Ansible
    inventory-compatible JSON.
  links:
    - title: dynamic-inventory - Boilerplate components for SQL-based Ansible dynamic inventory
      href: https://github.com/a-abella/dynamic-inventory

locateusers:
  title: Locate users on the network
  body: |
    No matter how many times it has been brought up, a large percentage of
    ticket submissions would come in with no identifying information on the
    affected workstation. Growing frustrated, I took matters into my own
    hands. I wrote a set of functions to search the organization's file
    servers for connected users and their respective connected IPs. Since
    every user accesses at least one file share, this was a fairly reliable
    method of discovery. And since it didn't rely on querying neighboring
    workstations, it was significantly faster than methods like PSTools'
    <code>PSLoggedOn.exe</code>.
  links:
    - title: locateUser.ps1 - Quickly find where a user is logged in
      href: https://github.com/a-abella/locateUser

statefulreboots:
  title: Stateful workstation reboots
  body: |
    For some unknown reason, our standard nightly workstation reboot GPO would
    fail to wake clients for the reboot task. Looking for alternative
    solutions, we decided on rebooting workstations after an explicit logout.
    However, disconnected sessions and the Switch User button meant that if a
    second user logged in and out, existing disconnected sessions would be
    lost on the reboot, even if that session was just one hour old while the
    user was out to lunch.<br /><br />

    By parsing <code>query user</code> output, we could reboot conditionally
    based on the state of active and disconnected sessions. We could even get
    the idle times of disconnected sessions to only reboot when we could
    consider it "safe." Doing this, we achieved our goal of frequent
    workstation reboots but without the data loss risk typically associated
    with such policies.
  links:
    - title: stateful-station-reboot.ps1 - Session-aware regular workstation restarts
      href: https://github.com/a-abella/stateful-station-reboot

ransomdetection:
  title: Ransomware detection with inotify
  body: |
    Most ransomware variants encrypt volumes recursive and usually traverse a
    file system alphabetically. Knowing this, we can lay bait for ransomware,
    and then sound the alarm when notice something suspicious. When working on
    my <a class="projlink" target="_self" href="#smbdfssetup">Samba DFS project</a>, I
    created world-writable hidden directories at the root of every share, and
    named them so they sat first in alphabetical order. In each directory were
    thousands of almost-empty plaintext files. Using <a class="projlink"
    href="https://github.com/rvoicilas/inotify-tools"><code>inotify-tools</code></a>
    to interface with Linux's <code>inotify()</code> function, I set up an
    inode watch on every file of each hidden directory. When a threshold value
    of files are modified or deleted, the server fires off an email containing
    the connection information of the user(s) and IP(s) accessing those bait
    files.<br /><br />

    While the encryption program takes its time to encrypt all the thousands
    of files (usually a handful of minutes), we are afforded the opportunity
    to verify and then kill the malicious process ID. To take it a step
    further, we can even block the IP on every shares' firewall with a single
    Ansible command. The process is further automatable by killing the PID and
    setting the firewall rule at another, higher threshold. Using this
    approach, we've lowered our average frequency of ransomware events
    (defined as events requiring a file system restore) from 1-2 per month to
    zero.
  links:
    - title: ransom-alarm.sh - Monitoring for ransomware and other intrusion
      href: https://github.com/a-abella/ransom-alarm.sh

smbdfssetup:
  title: Automated Samba share deployments for DFS
  body: |
    At my first organization, the existing network storage solution was a
    single Windows Share on bare metal. The server was about five years old
    and supported the entire 1,200 person organization. When ransomware got
    popular, the lack of a proper permissions structure left it very
    vulnerable to attack. I was tasked with decentralizing our storage, and
    the solution I devised was a multi-server, department-segregated Windows
    Domain DFS Namespace where the shared folders were actually Linux Samba
    shares. Through the Samba configuration I could "invisibly" fine-tune
    access control. Running the shares on Linux servers also gave me access to
    tools like <code>inotify()</code> and <code>auditd</code> for rudimentary
    intrusion detection.<br /><br />

    At final count, I was planning 11 separate shares on 7-8 separate CentOS 7
    hosts. To facilitate the deployment process, I developed a guided
    interactive script to automatically manage the Samba and Winbind
    configurations, as well as handle LVM management and base permissions.
  links:
    - title: smb-dfs-share-setup.py - Automated per-department Samba share configuration
      href: https://github.com/a-abella/smb-dfs-share-setup.py

adaccounttool:
  title: Bulk AD account management with Exchange support
  body: |
    My first systems administration position was in a call center, and among
    my responsibilities was Active Directory administration. Due to the nature
    of the call center business, customer service representative turnover
    rates were high enough that user account administration was a hassle.
    Especially in the holiday seasons, we would frequently receive lists of
    new hires and terminations <b>60+</b> users long. Prior to my scripted
    solution, the established method of administering user accounts was to
    manually create or delete them one-by-one in the AD Users & Groups GUI.
    Needless to say, as the new-hires and terminations lists grew longer, I
    grew more and more impatient.<br/><br/>

    My objective was to make the least annoying user management script I
    could. No pre-formatted CSV files needed, or anything or the sort. Just
    select an OU from a graphical dialog, paste in whole lists of proper names
    (with some minor formatting caveats), follow the prompts. Easy,
    annoyance-free, and greatly enhanced ticket turnaround time. There's still
    quite a few more features worth adding, but even now it's one of the more
    valuable tools I've created for myself.
  links:
    - title: usermanagement.ps1 - AD and Exchange account management
      href: https://github.com/a-abella/usermanagement.ps1

psnettools:
  title: Network querying & WakeOnLan with AD integration
  body: |
    When working on desktop inventory, provisioning, or deployment projects I
    would frequently need to monitor and maintain the online status of a
    subset of PCs within the organization. For example, when taking software
    inventory of only a single OU worth of PCs, I would first need to
    determine the sleep/wake status of all the PCs in the OU, wake the ones
    that are unresponsive, and keep them awake until the task has been
    completed. The company I worked at when I wrote these tools had a very
    "boots-on-ground" approach to this problem (i.e., walk to the computers
    and slap the spacebars), which I found less than efficient. I wrote these
    tools to solve that.
  links:
    - title: Wake-Send.ps1 - WakeOnLan packet constructor with AD integration
      href: https://github.com/a-abella/Wake-Send.ps1
    - title: Mass-Ping.ps1 - Quickly get online status of groups of hosts with AD integration
      href: https://github.com/a-abella/Mass-Ping.ps1

macscanner:
  title: Compiling MAC address data for WakeOnLan
  body: |
    Developed in conjunction with my <a class="projlink" target="_self"
    href="#psnettools">Wake-Send.ps1 PowerShell script</a>, I needed a reliable
    and up-to-date source of device MAC addresses on the network so I could
    construct a <a class="projlink"
    href="https://en.wikipedia.org/wiki/Wake-on-LAN#Magic_packet">magic
    packet</a> containing a target PC's MAC address data. Enter
    macscanner.sh. Parses <code>nmap</code> output, self-cleans repeat entries,
    is multi-hostname-aware, and requires no maintenance or afterthought. Runs
    on any Linux server you have lying around that's online on your target
    network. I run it on a 30 minute cron, and <code>scp</code> it to a network
    location where Wake-Send.ps1 can access it.
  links:
    - title: macscanner.sh source and documentation
      href: https://github.com/a-abella/macscanner.sh

seething:
  title: Seething Corruption Trainer
  body: |
    A simple Python script to help memorize the Seething Corruption
    positioning call-outs on World of Warcraft's Mythic Archimonde encounter.
    Written because I'm bad at getting over failure. Pretty much useless to
    anyone but myself.
  links:
    - title: Source and sample gif
      href: https://github.com/a-abella/seething-corruption-trainer

antonioabellacom:
  title: antonioabella.com
  body: |
    This site, hosted on a Digital Ocean Ubuntu LTS (14.04) VPS serving
    virtualhost pages with nginx and php-fpm. Created so I can hand out a
    website name and craftily appear to be a professional.
  links:
    - title: Page sources, configs, and changelogs
      href: https://github.com/a-abella/antonioabella.com

cvguild:
  title: Desktop and mobile sites, form in PHP and JQuery, VOIP services
  body: |
    A landing portal and application form for a World of Warcraft raiding
    guild, server as a virtual host on this same server. Implements php-fpm
    for form manipulation and jQuery 1.11.2 via Google CDN. The desktop
    landing page uses a parallax effect design created in pure CSS. The mobile
    site is responsively designed for any resolution by leveraging the CSS3
    viewport-height attribute. This server also hosts a Mumble VOIP server
    implementing SSL certificate validation for registered and elevated users.
  links:
    - title: Desktop landing page
      href: https://www.cv-guild.com
    - title: Mobile landing page
      href: https://m.cv-guild.com
    - title: PHP application form
      href: https://www.cv-guild.com/app.php
    - title: Desktop site page sources and configs
      href: https://github.com/a-abella/convictionguild
    - title: Mobile site page sources and configs
      href: https://github.com/a-abella/convictionmobile

fiuserver:
  title: CentOS 5.11 multi-role term project
  body: |
    A CentOS 5.11 server with SaltStack configuration management, several web
    services, Asterisk PBX, instant messaging server, extended logging
    services, backup management, network printing services, and more. Ran as a
    guest within a VMWare ESXi 5.5 host.
  links:
    - title: Configs, binaries, and served web pages
      href: https://github.com/a-abella/centos-server
    - title: All documentation as plaintext
      href: docs/centosdocs/howtopage.html

adhomelab:
  title: Windows AD/Exchange virtual lab
  body: |
    A virtual network hosted on VMWare Workstation 11 consisting of two
    Windows Server 2012 R2 servers, one CentOS 7 server, one Windows 7
    Professional client, one Mac OS X 10.11 client, and one CentOS 7 client.
    One Server 2012 instance runs Active Directory, DNS, DHCP, and Routing and
    Remote Access to serve as a border router granting the virtual network
    internet connectivity. The second Server 2012 instance runs Exchange and
    IIS. The Linux server runs Apache and other miscellaneous services. The
    Linux machines authenticate to Active Directory with Samba/Kerberos, and
    the OS X client binds to AD with the in-built OS X OpenDirectory
    utilities.
  links:
    - title: Configs and documentation
      href: docs/adlabdocs/adlabindex.html

kvm:
  title: Linux KVM hypervisor with KVM/Qemu Windows instance using IOMMU
  body: |
    A typical workstation machine running Arch Linux as the host alongside a
    Windows VM via KVM/Qemu. IOMMU (Input/Output Memory Management Unit)
    allows certain hypervisors to take control of assigned hardware devices
    including PCI controllers. In this application I pass a discrete GPU to
    the Windows VM which allows up to 95% of the native graphical performance
    within the VM enabling certain GPU intensive tasks such as gaming, video
    rendering, and hardware accelerated decode of very high resolution video.
    The two machines run concurrently with each GPU connected to its own
    monitor.
  links:
    - title: KVM/Qemu Configurations
      href: ""
    - title: Scripts and additional configurations
      href: ""
    - title: Extended explanations and instructions
      href: ""
